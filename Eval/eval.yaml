dataset: Nvsept6new

generate_ground_truth: false

questions_generator:
    prompt: "default"
    num_questions_per_chunk: 1
    max_chunks: 10     # Maximum number of chunks to be used for question generation
    llm: dkubex
    llm_url: http://34.210.206.27:30002/v1/
    llmkey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoib2NkbGdpdCIsInR5cGUiOiJhcGkiLCJpZCI6Ii9kZXBsb3ltZW50L2xsYW1hMzFkZW1vLyJ9.6WEJk7GpRpydCcW6ymMTapSCcnRFzAiTvNdCGgjQrJQ
    max_tokens: 2048

# ground_truth: /home/ocdlgit/demo-gi/updatedGT.csv
ground_truth: /home/data/GIconfigs/updated_groudtruth_sept_23_539.csv

rag_configuration: /home/data/GIconfigs/queryrewrite/rag_GI.yaml

vectorstore: weaviate_vectorstore
weaviate_vectorstore:
    url: ""
    auth_key: ""
    provider: dkubex
    properties:
    - paperchunks
    - dkubexfm

evaluator:
  - semantic_similarity_evaluator       # Vector Similarity
  - correctness_evaluator               # LLM Similarity
  - answer_relevancy_evaluator
  - retrieval_evaluator

semantic_similarity_evaluator:
    prompt: "default"
    metrics:
    - similarity_score

correctness_evaluator:
    # prompt: default
    # prompt: |
    #     Please act as an impartial judge and evaluate the similarity of the response provided by
    #     an assistant against the reference answer for user question below.
    #     You will be given a reference answer and the assistant's answer.
    #     Your job is to compare the assistant's answer with the reference answer for similarity
    #     in the context of the user's question.
    #     Provide a score between 1 and 10 with an interval of 1
    #     Do not allow the length of the response to influence your evaluation.
    prompt: |
        You are an expert evaluation system for a question answering chatbot.

        You are given the following information:
        - a user query, and
        - a generated answer

        You may also be given a reference answer to use for reference in your evaluation.

        Your job is to judge the relevance and correctness of the generated answer.
        Output a single score that represents a holistic evaluation.
        You must return your response in a line with only the score.
        Do not return answers in any other format.
        On a separate line provide your reasoning for the score as well.

        Please act as an impartial judge and evaluate the similarity of the response provided by
        an assistant against the reference answer for user question below.
        You will be given a reference answer and the assistant's answer.
        Your job is to compare the assistant's answer with the reference answer for similarity
        in the context of the user's question.
        Provide a score between 1 and 10 with an interval of 1
        Do not allow the length of the response to influence your evaluation.
    llm: dkubex
    llm_url: http://54.160.139.85:30001/v1/ 
    llmkey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoic2lyZWVzaGEtbWFuZGF2YSIsInR5cGUiOiJhcGkiLCJpZCI6Ii9kZXBsb3ltZW50L2xsYW1hMzFkZXY4ay8ifQ.SyAxzCYseOTNagLwTjvN0KKqmG9IsYZToaKCFXpXN9A
    # llm_url: "http://54.224.196.34:30005/v1/"
    # llmkey: "abcd1234"
    max_tokens: 2048

# cross_vector_similarity_evaluator:
#     prompt: "default"
#     llm: openai         # dkubex
#     llmkey: "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" # <llmkey?
#     llm_url: ""             # http://54.179.35.250:30002/v1/
#     max_tokens: 2048
#     rag_configuration: "/home/sai-bandela/simple_rag.yaml"

answer_relevancy_evaluator:
    prompt: "default"
    llm: dkubex
    llm_url: http://54.160.139.85:30001/v1/
    llmkey: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoic2lyZWVzaGEtbWFuZGF2YSIsInR5cGUiOiJhcGkiLCJpZCI6Ii9kZXBsb3ltZW50L2xsYW1hMzFkZXY4ay8ifQ.SyAxzCYseOTNagLwTjvN0KKqmG9IsYZToaKCFXpXN9A
    max_tokens: 2048

retrieval_evaluator:
    weaviate_vectorstore:
        kind: weaviate
        vectorstore_provider: dkubex
        textkey: paperdocs
        # embedding_class: HuggingFaceEmbedding               # Use 'HuggingFaceEmbedding' for embedding models from HuggingFace, or 'OpenAIEmbedding' for OpenAI embeddings
        # embedding_model: "BAAI/bge-large-en-v1.5"           # Embedding model name
        ### dkubex embedding config
        embedding_provider: "sky"
        embedding_url: http://54.160.139.85:30002/v1/
        embedding_key: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoic2lyZWVzaGEtbWFuZGF2YSIsInR5cGUiOiJhcGkiLCJpZCI6Ii9kZXBsb3ltZW50L2JnZWRldi8ifQ.RxtyidxNl8k7W9W0Z7gw0694VwFB8vIxo3ZR4_svqE0
        llmkey: ""                                          # API key for the embedding model (if required)
        similarity_top_k: 3
    metrics:
    - mrr
    - hit_rate

tracking:
    experiment: gi-run1-26sept
