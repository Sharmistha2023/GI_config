dataset:
context_combiner:
  use_adj_chunks: True  #True

vectorstore: weaviate_vectorstore
embedding: sky   #openai  #dkubex #sky #huggingface
search: vector_search

query:
  post_processor:
    - acronym_expander
    - query_rewrite

acronym_expander:
  acr_file: "/home/data/GI_config/cache_enabled/nv_acronym.json"

query_rewrite:
  confidence_threshold: 1
  system_prompt: "/home/data/GI_config/nv_system_prompt.txt"
  user_prompt: "/home/data/GI_config/nv-usr-prompt-new.yaml"

synthesizer:
  use_adjacent_chunks: True
  prompt: |
      "Your job is to extract relevant context for the user's question. "
      "Never directly answer yes or no, but only provide policy or procedural information from relevant sections "
      "Do not assume anything. Use the context and not any prior learnings. "
      "Please limit the output to 100 words. "
      "Please do not include any explanatory logic or notes. "
      "For each part of your answer, indicate which sources most support it "
      "via valid citation markers at the end of sentences, like (Example2012). "
      "Note that pregnancy is not a QLE, but child birth is a QLE. \n"
      "Include sources used at the end of the response"
      "Include confidence score of the generated summary on the scale of 1 to 10 \n"
      "Do not explain Confidence score or Context. Do not generate anything after generating confidence score.  \n"
      "If the context provides insufficient information reply I cannot answer, Please escalate to supervisor or rephrase the question and don't provide any further information. "
      "If the context provides sufficient information reply strictly in the format; Answer: ...\n Sources: ...\n Confidence score: ... "
      "Context:\n {context_str}\n"
      "Question: {query_str}\n"
      "Answer: "
        #max_tokens: 1024
  llm: dkubex
  llm_url: "http://54.162.17.163:30002/v1/"
  llmkey: "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoic2hydXRoaS1zcmVlIiwidHlwZSI6ImFwaSIsImlkIjoiL2RlcGxveW1lbnQvbGFtYTM4ay8ifQ.UNHoIVo8Si757Pfr1dezy_RoGvc38DV8-fHEcZP_8Kg"
  window_size: 2
  max_tokens: 1024

mlflow:
  experiment: Rag_9oct_2024

huggingface:
  model: "BAAI/bge-large-en-v1.5"

sky:
  embedding_url: "http://54.162.17.163:30001/v1/"
  embedding_key:  "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyIjoic2hydXRoaS1zcmVlIiwidHlwZSI6ImFwaSIsImlkIjoiL2RlcGxveW1lbnQvYmdlLyJ9.O9xhGB4HS0C6Z-Jhh46DFynCUtbE53nY1rNrdKsZCD4"

faq:
  enabled: true
  threshold: 0.90

vector_search:
  top_k: 3
  rerank: true
  rerank_topk: 5
  max_sources: 3

weaviate_vectorstore:
  vectorstore_provider: dkubex
  url: ""
  auth_key: ""
  textkey: 'paperchunks'

securellm:
  appkey: "sk-agf2qra-weju3jq-vgulufy-ibi5uqi"
  dkubex_url: "https://ad46449457b5e4d7fbc99eb01dc7dbc8-ba8182fca0a35e00.elb.us-east-1.amazonaws.com/"
